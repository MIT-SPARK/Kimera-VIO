/* ----------------------------------------------------------------------------
 * Copyright 2017, Massachusetts Institute of Technology,
 * Cambridge, MA 02139
 * All Rights Reserved
 * Authors: Luca Carlone, et al. (see THANKS for the full author list)
 * See LICENSE for the license information
 * -------------------------------------------------------------------------- */

/**
 * @file   testLoopClosureDetector.cpp
 * @brief  test LoopClosureDetector
 * @author Marcus Abate, Luca Carlone
 */

#include <memory>
#include <string>
#include <utility>
#include <vector>

#include <gflags/gflags.h>
#include <glog/logging.h>
#include <gtest/gtest.h>

#include "kimera-vio/frontend/CameraParams.h"
#include "kimera-vio/frontend/Frame.h"
#include "kimera-vio/frontend/StereoFrame.h"
#include "kimera-vio/frontend/Tracker.h"
#include "kimera-vio/frontend/feature-detector/FeatureDetector.h"
#include "kimera-vio/loopclosure/LoopClosureDetector.h"
#include "kimera-vio/utils/UtilsOpenCV.h"

DECLARE_string(test_data_path);
DECLARE_string(vocabulary_path);

namespace VIO {

class LCDFixture :public ::testing::Test {
 protected:
  // Tolerances
  const double tol = 1e-7;
  const double rot_tol = 0.05;
  const double tran_tol = 0.20;

 public:
  LCDFixture()
      : lcd_test_data_path_(FLAGS_test_data_path +
                            std::string("/ForLoopClosureDetector")),
        lcd_detector_(nullptr),
        ref1_to_cur1_pose_(),
        ref2_to_cur2_pose_(),
        ref1_stereo_frame_(nullptr),
        ref2_stereo_frame_(nullptr),
        cur1_stereo_frame_(nullptr),
        cur2_stereo_frame_(nullptr),
        id_ref1_(0),
        id_cur1_(1),
        id_ref2_(2),
        id_cur2_(3),
        timestamp_ref1_(1000),
        timestamp_cur1_(2000),
        timestamp_ref2_(3000),
        timestamp_cur2_(4000) {
    // First set value of vocabulary path for LoopClosureDetector
    FLAGS_vocabulary_path = "../vocabulary/ORBvoc.yml";

    LoopClosureDetectorParams params;
    params.parseYAML(lcd_test_data_path_+"/testLCDParameters.yaml");

    FLAGS_vocabulary_path =
        FLAGS_test_data_path +
        std::string("/ForLoopClosureDetector/small_voc.yml.gz");

    lcd_detector_ = VIO::make_unique<LoopClosureDetector>(params);

    ref1_pose_ = gtsam::Pose3(
        gtsam::Rot3(gtsam::Quaternion(0.338337, 0.608466, -0.535476, 0.478082)),
        gtsam::Point3(1.573832, 2.023348, 1.738755));

    cur1_pose_ = gtsam::Pose3(
        gtsam::Rot3(gtsam::Quaternion(0.478634, 0.415595, -0.700197, 0.328505)),
        gtsam::Point3(1.872115, 1.786064, 1.586159));

    ref2_pose_ = gtsam::Pose3(
        gtsam::Rot3(gtsam::Quaternion(0.3394, -0.672895, -0.492724, -0.435018)),
        gtsam::Point3(-0.662997, -0.495046, 1.347300));

    cur2_pose_ = gtsam::Pose3(
        gtsam::Rot3(gtsam::Quaternion(0.39266, -0.590667, -0.58023, -0.400326)),
        gtsam::Point3(-0.345638, -0.501712, 1.320441));

    ref1_to_cur1_pose_ = ref1_pose_.between(cur1_pose_);
    ref2_to_cur2_pose_ = ref2_pose_.between(cur2_pose_);

    initializeData();
  }

 protected:
  void initializeData() {
    // Initialize CameraParams for both frames
    CameraParams cam_params_left, cam_params_right;
    cam_params_left.parseYAML(lcd_test_data_path_+"/sensorLeft.yaml");
    cam_params_right.parseYAML(lcd_test_data_path_+"/sensorRight.yaml");

    std::string img_name_ref1_left = lcd_test_data_path_ + "/left_img_0.png";
    std::string img_name_ref1_right = lcd_test_data_path_ + "/right_img_0.png";

    std::string img_name_cur1_left = lcd_test_data_path_ + "/left_img_1.png";
    std::string img_name_cur1_right = lcd_test_data_path_ + "/right_img_1.png";

    std::string img_name_ref2_left = lcd_test_data_path_ + "/left_img_2.png";
    std::string img_name_ref2_right = lcd_test_data_path_ + "/right_img_2.png";

    std::string img_name_cur2_left = lcd_test_data_path_ + "/left_img_3.png";
    std::string img_name_cur2_right = lcd_test_data_path_ + "/right_img_3.png";

    // Initialize StereoFrame objects for reference and current frames
    FrontendParams tp;
    FeatureDetectorParams fdp;
    FeatureDetector feature_detector(fdp);

    ref1_stereo_frame_ = VIO::make_unique<StereoFrame>(
        id_ref1_,
        timestamp_ref1_,
        UtilsOpenCV::ReadAndConvertToGrayScale(
            img_name_ref1_left, tp.stereo_matching_params_.equalize_image_),
        cam_params_left,
        UtilsOpenCV::ReadAndConvertToGrayScale(
            img_name_ref1_right, tp.stereo_matching_params_.equalize_image_),
        cam_params_right,
        tp.stereo_matching_params_);

    feature_detector.featureDetection(ref1_stereo_frame_->getLeftFrameMutable());
    CHECK(ref1_stereo_frame_);
    ref1_stereo_frame_->setIsKeyframe(true);
    ref1_stereo_frame_->sparseStereoMatching();

    cur1_stereo_frame_ = VIO::make_unique<StereoFrame>(
        id_cur1_,
        timestamp_cur1_,
        UtilsOpenCV::ReadAndConvertToGrayScale(
            img_name_cur1_left, tp.stereo_matching_params_.equalize_image_),
        cam_params_left,
        UtilsOpenCV::ReadAndConvertToGrayScale(
            img_name_cur1_right, tp.stereo_matching_params_.equalize_image_),
        cam_params_right,
        tp.stereo_matching_params_);

    feature_detector.featureDetection(cur1_stereo_frame_->getLeftFrameMutable());
    CHECK(cur1_stereo_frame_);
    cur1_stereo_frame_->setIsKeyframe(true);
    cur1_stereo_frame_->sparseStereoMatching();

    ref2_stereo_frame_ = VIO::make_unique<StereoFrame>(
        id_ref2_,
        timestamp_ref2_,
        UtilsOpenCV::ReadAndConvertToGrayScale(
            img_name_ref2_left, tp.stereo_matching_params_.equalize_image_),
        cam_params_left,
        UtilsOpenCV::ReadAndConvertToGrayScale(
            img_name_ref2_right, tp.stereo_matching_params_.equalize_image_),
        cam_params_right,
        tp.stereo_matching_params_);

    feature_detector.featureDetection(ref2_stereo_frame_->getLeftFrameMutable());
    CHECK(ref2_stereo_frame_);
    ref2_stereo_frame_->setIsKeyframe(true);
    ref2_stereo_frame_->sparseStereoMatching();

    cur2_stereo_frame_ = VIO::make_unique<StereoFrame>(
        id_cur2_,
        timestamp_cur2_,
        UtilsOpenCV::ReadAndConvertToGrayScale(
            img_name_cur2_left, tp.stereo_matching_params_.equalize_image_),
        cam_params_left,
        UtilsOpenCV::ReadAndConvertToGrayScale(
            img_name_cur2_right, tp.stereo_matching_params_.equalize_image_),
        cam_params_right,
        tp.stereo_matching_params_);

    feature_detector.featureDetection(cur2_stereo_frame_->getLeftFrameMutable());
    CHECK(cur2_stereo_frame_);
    cur2_stereo_frame_->setIsKeyframe(true);
    cur2_stereo_frame_->sparseStereoMatching();

    // Set intrinsics for essential matrix calculation:
    CHECK(lcd_detector_);
    lcd_detector_->setIntrinsics(*ref1_stereo_frame_);
  }

  // Standard gtest methods, unnecessary for now
  virtual void SetUp() {}
  virtual void TearDown() {}

 protected:
  // Data-related members
  std::string lcd_test_data_path_;

  // LCD members
  std::unique_ptr<LoopClosureDetector> lcd_detector_;

  // Stored frame members
  gtsam::Pose3 ref1_pose_, ref2_pose_, cur1_pose_, cur2_pose_;
  gtsam::Pose3 ref1_to_cur1_pose_, ref2_to_cur2_pose_;
  std::unique_ptr<StereoFrame> ref1_stereo_frame_, cur1_stereo_frame_;
  std::unique_ptr<StereoFrame> ref2_stereo_frame_, cur2_stereo_frame_;
  const FrameId id_ref1_;
  const FrameId id_cur1_;
  const FrameId id_ref2_;
  const FrameId id_cur2_;
  const VIO::Timestamp timestamp_ref1_;
  const VIO::Timestamp timestamp_cur1_;
  const VIO::Timestamp timestamp_ref2_;
  const VIO::Timestamp timestamp_cur2_;
};  // class LCDFixture

TEST_F(LCDFixture, defaultConstructor) {
  /* Test default constructor to ensure that vocabulary is loaded correctly. */
  CHECK(lcd_detector_);
  EXPECT_GT(lcd_detector_->getBoWDatabase()->getVocabulary()->size(), 0);
}

TEST_F(LCDFixture, rewriteStereoFrameFeatures) {
  /* Test the replacement of StereoFrame keypoints, versors, etc with ORB */
  float keypoint_diameter = 2;
  unsigned int nfeatures = 500;

  CHECK(ref1_stereo_frame_);
  StereoFrame stereo_frame = *ref1_stereo_frame_;

  std::vector<cv::KeyPoint> keypoints;
  keypoints.reserve(nfeatures);

  for (unsigned int i = 0; i < nfeatures; i++) {
    keypoints.push_back(cv::KeyPoint(5, i, keypoint_diameter));
  }

  lcd_detector_->rewriteStereoFrameFeatures(keypoints, &stereo_frame);

  // TODO(marcus): Don't need mutable frames!

  const Frame& left_frame = stereo_frame.getLeftFrame();
  const Frame& right_frame = stereo_frame.getRightFrame();

  EXPECT_EQ(left_frame.keypoints_.size(), nfeatures);
  EXPECT_EQ(right_frame.keypoints_.size(), nfeatures);
  EXPECT_EQ(left_frame.versors_.size(), nfeatures);
  EXPECT_EQ(left_frame.scores_.size(), nfeatures);

  for (unsigned int i = 0; i < left_frame.keypoints_.size(); i++) {
    EXPECT_EQ(left_frame.keypoints_[i], keypoints[i].pt);
    EXPECT_EQ(left_frame.versors_[i],
              Frame::calibratePixel(keypoints[i].pt, left_frame.cam_param_));
  }

  EXPECT_EQ(stereo_frame.keypoints_3d_.size(), nfeatures);
  EXPECT_EQ(stereo_frame.keypoints_depth_.size(), nfeatures);
  EXPECT_EQ(stereo_frame.left_keypoints_rectified_.size(), nfeatures);
  EXPECT_EQ(stereo_frame.right_keypoints_rectified_.size(), nfeatures);
}

TEST_F(LCDFixture, processAndAddFrame) {
  /* Test adding frame to database without BoW Loop CLosure Detection */
  CHECK(lcd_detector_);
  EXPECT_EQ(lcd_detector_->getFrameDatabasePtr()->size(), 0);

  FrameId id_0 = lcd_detector_->processAndAddFrame(*ref1_stereo_frame_);

  EXPECT_EQ(id_0, 0);
  EXPECT_EQ(lcd_detector_->getFrameDatabasePtr()->size(), 1);
  EXPECT_EQ(lcd_detector_->getFrameDatabasePtr()->at(0).timestamp_,
            timestamp_ref1_);
  EXPECT_EQ(lcd_detector_->getFrameDatabasePtr()->at(0).id_kf_, id_ref1_);
  EXPECT_EQ(lcd_detector_->getFrameDatabasePtr()->at(0).keypoints_.size(),
            lcd_detector_->getLCDParams().nfeatures_);

  FrameId id_1 = lcd_detector_->processAndAddFrame(*cur1_stereo_frame_);

  EXPECT_EQ(id_1, 1);
  EXPECT_EQ(lcd_detector_->getFrameDatabasePtr()->size(), 2);
  EXPECT_EQ(lcd_detector_->getFrameDatabasePtr()->at(1).timestamp_,
            timestamp_cur1_);
  EXPECT_EQ(lcd_detector_->getFrameDatabasePtr()->at(1).id_kf_, id_cur1_);
  EXPECT_EQ(lcd_detector_->getFrameDatabasePtr()->at(1).keypoints_.size(),
            lcd_detector_->getLCDParams().nfeatures_);
}

TEST_F(LCDFixture, geometricVerificationCheck) {
  /* Test geometric verification using RANSAC Nister 5pt method */
  CHECK(lcd_detector_);
  CHECK(ref1_stereo_frame_);
  CHECK(cur1_stereo_frame_);
  lcd_detector_->processAndAddFrame(*ref1_stereo_frame_);
  lcd_detector_->processAndAddFrame(*cur1_stereo_frame_);

  gtsam::Pose3 camRef1_T_camCur1_mono;
  lcd_detector_->geometricVerificationCheck(1, 0, &camRef1_T_camCur1_mono);

  gtsam::Pose3 ref_to_cur_gnd_truth_pose =
      gtsam::Pose3(ref1_to_cur1_pose_.rotation(), ref1_to_cur1_pose_.translation());

  gtsam::Pose3 bodyRef1_T_bodyCur1;
  lcd_detector_->transformCameraPoseToBodyPose(camRef1_T_camCur1_mono,
                                               &bodyRef1_T_bodyCur1);

  std::pair<double, double> error =
      UtilsOpenCV::ComputeRotationAndTranslationErrors(
          ref_to_cur_gnd_truth_pose, bodyRef1_T_bodyCur1, false);

  EXPECT_LT(error.first, rot_tol);
  // TODO(marcus): This test doesn't pass with realistic error tolerances
  EXPECT_LT(error.second, tran_tol * 2.5);
}

TEST_F(LCDFixture, recoverPoseArun) {
  /* Test proper scaled pose recovery between two identical images */
  CHECK(lcd_detector_);
  lcd_detector_->getLCDParamsMutable()->pose_recovery_option_ =
      PoseRecoveryOption::RANSAC_ARUN;
  gtsam::Pose3 empty_pose;
  std::pair<double, double> error;

  /* Test proper scaled pose recovery between ref and cur images */
  CHECK(ref1_stereo_frame_);
  CHECK(cur1_stereo_frame_);
  lcd_detector_->processAndAddFrame(*ref1_stereo_frame_);
  lcd_detector_->processAndAddFrame(*cur1_stereo_frame_);

  gtsam::Pose3 pose_1;
  lcd_detector_->recoverPose(1, 0, empty_pose, &pose_1);

  error = UtilsOpenCV::ComputeRotationAndTranslationErrors(ref1_to_cur1_pose_,
                                                           pose_1, true);

  EXPECT_LT(error.first, rot_tol);
  EXPECT_LT(error.second, tran_tol);

  /* Test proper scaled pose recovery between extra and extra_2 images */
  // TODO(marcus): fail this test, likely because extra is just too hard
  // lcd_detector_->processAndAddFrame(*ref2_stereo_frame_);
  // lcd_detector_->processAndAddFrame(*cur2_stereo_frame_);
  //
  // gtsam::Pose3 pose_2;
  // lcd_detector_->recoverPose(3, 2, empty_pose, &pose_2);
  //
  // error = UtilsOpenCV::ComputeRotationAndTranslationErrors(
  //     ref2_to_cur2_pose_, pose_2, true);
  //
  // EXPECT_LT(error.first, rot_tol);
  // EXPECT_LT(error.second, tran_tol);
}

TEST_F(LCDFixture, recoverPoseGivenRot) {
  CHECK(lcd_detector_);
  lcd_detector_->getLCDParamsMutable()->pose_recovery_option_ =
      PoseRecoveryOption::GIVEN_ROT;

  gtsam::Pose3 body_input_pose, cam_input_pose;
  std::pair<double, double> error;

  /* Test pose recovery given ground truth rotation and unit translation */
  CHECK(ref1_stereo_frame_);
  CHECK(cur1_stereo_frame_);
  lcd_detector_->processAndAddFrame(*ref1_stereo_frame_);
  lcd_detector_->processAndAddFrame(*cur1_stereo_frame_);

  body_input_pose = gtsam::Pose3(ref1_to_cur1_pose_.rotation(),
                                 ref1_to_cur1_pose_.translation() /
                                     ref1_to_cur1_pose_.translation().norm());
  lcd_detector_->transformBodyPoseToCameraPose(body_input_pose,
                                               &cam_input_pose);

  gtsam::Pose3 pose_0_1;
  lcd_detector_->recoverPose(1, 0, cam_input_pose, &pose_0_1);

  error = UtilsOpenCV::ComputeRotationAndTranslationErrors(ref1_to_cur1_pose_,
                                                           pose_0_1, false);
  EXPECT_LT(error.first, rot_tol);
  EXPECT_LT(error.second, tran_tol);

  /* Test pose recovery on other two images */
  CHECK(ref2_stereo_frame_);
  CHECK(cur2_stereo_frame_);
  FrameId frm_2 = lcd_detector_->processAndAddFrame(*ref2_stereo_frame_);
  FrameId frm_3 = lcd_detector_->processAndAddFrame(*cur2_stereo_frame_);

  body_input_pose = gtsam::Pose3(ref2_to_cur2_pose_.rotation(),
                                 ref2_to_cur2_pose_.translation() /
                                     ref2_to_cur2_pose_.translation().norm());
  lcd_detector_->transformBodyPoseToCameraPose(body_input_pose,
                                               &cam_input_pose);

  gtsam::Pose3 pose_2_3;
  lcd_detector_->recoverPose(3, 2, cam_input_pose, &pose_2_3);

  error = UtilsOpenCV::ComputeRotationAndTranslationErrors(ref2_to_cur2_pose_,
                                                           pose_2_3, true);
  EXPECT_LT(error.first, rot_tol);
  EXPECT_LT(error.second, tran_tol);
}

TEST_F(LCDFixture, detectLoop) {
  std::pair<double, double> error;

  CHECK(lcd_detector_);
  lcd_detector_->getLCDParamsMutable()->pose_recovery_option_ =
      PoseRecoveryOption::GIVEN_ROT;

  /* Test the detectLoop method against two images without closure */
  LoopResult loop_result_0, loop_result_1, loop_result_2, loop_result_3;

  CHECK(ref1_stereo_frame_);
  CHECK(ref2_stereo_frame_);
  CHECK(cur1_stereo_frame_);
  lcd_detector_->detectLoop(*ref2_stereo_frame_, &loop_result_0);
  EXPECT_EQ(loop_result_0.isLoop(), false);

  lcd_detector_->detectLoop(*ref1_stereo_frame_, &loop_result_1);
  EXPECT_EQ(loop_result_1.isLoop(), false);

  /* Test the detectLoop method against two images that are identical */
  // TODO(marcus): why isn't geom_check working for two identical images?
  lcd_detector_->detectLoop(*ref1_stereo_frame_, &loop_result_2);
  // EXPECT_EQ(output_payload_2.is_loop_, true);
  // EXPECT_EQ(output_payload_2.timestamp_kf_, timestamp_ref1_);
  // EXPECT_EQ(output_payload_2.id_recent_, id_ref1_);
  // EXPECT_EQ(output_payload_2.id_match_, id_ref1_);
  // EXPECT_TRUE(output_payload_2.relative_pose_.equals(gtsam::Pose3(
  //     gtsam::Rot3::identity(), gtsam::Point3(0,0,0)), tol));

  /* Test the detectLoop method against two unidentical, similar images */
  lcd_detector_->detectLoop(*cur1_stereo_frame_, &loop_result_3);
  EXPECT_EQ(loop_result_3.isLoop(), true);
  EXPECT_EQ(loop_result_3.match_id_, 1);
  EXPECT_EQ(loop_result_3.query_id_, 3);

  error = UtilsOpenCV::ComputeRotationAndTranslationErrors(
      ref1_to_cur1_pose_, loop_result_3.relative_pose_, true);

  EXPECT_LT(error.first, rot_tol);
  EXPECT_LT(error.second, tran_tol);
}

TEST_F(LCDFixture, addOdometryFactorAndOptimize) {
  /* Test the addition of odometry factors to the PGO */
  CHECK(lcd_detector_);
  lcd_detector_->initializePGO();
  lcd_detector_->addOdometryFactorAndOptimize(
      VIO::OdometryFactor(1, gtsam::Pose3(),
          gtsam::noiseModel::Isotropic::Variance(6, 0.1)));

  VIO::OdometryFactor odom_factor(2, ref1_pose_,
      gtsam::noiseModel::Isotropic::Variance(6, 0.1));
  lcd_detector_->addOdometryFactorAndOptimize(odom_factor);

  gtsam::Values pgo_trajectory = lcd_detector_->getPGOTrajectory();
  gtsam::NonlinearFactorGraph pgo_nfg = lcd_detector_->getPGOnfg();

  EXPECT_EQ(pgo_trajectory.size(), 2);
  EXPECT_EQ(pgo_nfg.size(), 1);
}

TEST_F(LCDFixture, addLoopClosureFactorAndOptimize) {
  /* Test the addition of odometry and loop closure factors to the PGO */
  CHECK(lcd_detector_);
  lcd_detector_->initializePGO();
  VIO::OdometryFactor odom_factor_1(1, ref1_pose_,
      gtsam::noiseModel::Isotropic::Variance(6, 0.1));
  VIO::OdometryFactor odom_factor_2(2, cur1_pose_,
      gtsam::noiseModel::Isotropic::Variance(6, 0.1));
  VIO::LoopClosureFactor lc_factor_1_2(1, 2, ref1_to_cur1_pose_,
      gtsam::noiseModel::Isotropic::Variance(6, 0.1));

  lcd_detector_->addOdometryFactorAndOptimize(odom_factor_1);
  lcd_detector_->addOdometryFactorAndOptimize(odom_factor_2);
  lcd_detector_->addLoopClosureFactorAndOptimize(lc_factor_1_2);

  gtsam::Values pgo_trajectory = lcd_detector_->getPGOTrajectory();
  gtsam::NonlinearFactorGraph pgo_nfg = lcd_detector_->getPGOnfg();

  EXPECT_EQ(pgo_trajectory.size(), 2);
  EXPECT_EQ(pgo_nfg.size(), 1);
}

TEST_F(LCDFixture, spinOnce) {
  /* Test the full pipeline with one loop closure and full PGO optimization */
  CHECK(lcd_detector_);
  CHECK(ref1_stereo_frame_);
  LcdOutput::Ptr output_0 = lcd_detector_->spinOnce(LcdInput(
      timestamp_ref1_, FrameId(1), *ref1_stereo_frame_, gtsam::Pose3()));

  CHECK(ref2_stereo_frame_);
  LcdOutput::Ptr output_1 = lcd_detector_->spinOnce(LcdInput(
      timestamp_ref2_, FrameId(2), *ref2_stereo_frame_, gtsam::Pose3()));

  CHECK(cur1_stereo_frame_);
  LcdOutput::Ptr output_2 = lcd_detector_->spinOnce(LcdInput(
      timestamp_cur1_, FrameId(3), *cur1_stereo_frame_, gtsam::Pose3()));

  EXPECT_EQ(output_0->is_loop_closure_, false);
  EXPECT_EQ(output_0->timestamp_kf_, 0);
  EXPECT_EQ(output_0->timestamp_query_, 0);
  EXPECT_EQ(output_0->timestamp_match_, 0);
  EXPECT_EQ(output_0->id_match_, 0);
  EXPECT_EQ(output_0->id_recent_, 0);
  EXPECT_EQ(output_0->states_.size(), 1);
  EXPECT_EQ(output_0->nfg_.size(), 1);

  EXPECT_EQ(output_1->is_loop_closure_, false);
  EXPECT_EQ(output_1->timestamp_kf_, 0);
  EXPECT_EQ(output_1->timestamp_query_, 0);
  EXPECT_EQ(output_1->timestamp_match_, 0);
  EXPECT_EQ(output_1->id_match_, 0);
  EXPECT_EQ(output_1->id_recent_, 0);
  EXPECT_EQ(output_1->states_.size(), 2);
  EXPECT_EQ(output_1->nfg_.size(), 2);

  EXPECT_EQ(output_2->is_loop_closure_, true);
  EXPECT_EQ(output_2->timestamp_kf_, timestamp_cur1_);
  EXPECT_EQ(output_2->timestamp_query_, timestamp_cur1_);
  EXPECT_EQ(output_2->timestamp_match_, timestamp_ref1_);
  EXPECT_EQ(output_2->id_match_, 0);
  EXPECT_EQ(output_2->id_recent_, 2);
  EXPECT_EQ(output_2->states_.size(), 3);
}

}  // namespace VIO
